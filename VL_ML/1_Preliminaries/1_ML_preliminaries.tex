\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[usenames, dvipsnames]{xcolor}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{thmtools}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[part]
\newtheorem{subdefinition}{Definition}[definition]

\declaretheorem[sibling=definition, shaded={rulecolor=black, rulewidth=0.8pt, 
	bgcolor={rgb}{1,1,1}},name=Definition]{boxeddef}
\declaretheorem[sibling=subdefinition, shaded={rulecolor=black, rulewidth=0.5pt, 
	bgcolor={rgb}{1,1,1}},name=Definition]{boxedsubdef}

\theoremstyle{plain}
\newtheorem{example}{Example}[definition]

\title{Machine Learning 2023}
\author{David Graf}
\date{\today}
\begin{document}
\maketitle
\part{Preliminaries}
\begin{boxeddef}[$\sigma$-Algebra]
	Let $\mathcal{S}$ be a non-empty set. A family of sets $\mathcal{F} \subset \mathcal{P}(\mathcal{S})$ is called a \textcolor{red}{$\sigma$-Algebra} on $\mathcal{S}$, if the following conditions hold:
	\begin{itemize}
		\item $\mathcal{S} \in \mathcal{F}$
		\item From $ A \in \mathcal{F}$, it follows that $\mathcal{A}^c = \mathcal{S} \setminus \mathcal{A} \ \ \in \mathcal{F}$
		\item From $ A_i \in \mathcal{F}$, $i \in \mathbb{N}$, it follows that $$
			\bigcup_{i=1}^{\infty} A_i \  \in \mathcal{F}$$
	\end{itemize}
\end{boxeddef}

\paragraph{Remark:} Any subset $\mathcal{F} \in \mathcal{P}(\mathcal{S})$ is called a family of sets.\\

Smallest $\sigma$-Algebra over $\mathcal{S}$: $\{\emptyset, \mathcal{S}\}$\\

$\sigma$-Algebra generated by A: if $A \in \mathcal{S}$, then,$$
\sigma(A) = \{\emptyset, A, A^c, \mathcal{S}\}
$$
is the $\sigma$-Algebra generated by A.\\

\begin{boxeddef}[Generator]
	\label{generator}
	Given $\varepsilon \subset \mathcal{P}(\mathcal{S})$ (a family of sets) and $\Sigma$ denoting the set of \underline{all} $\sigma$-Algebras that contain $\varepsilon$, we call\\
	$$\sigma(\varepsilon) = \bigcap_{\mathcal{F} \in \mathcal{S}} \mathcal{F}$$
	the $\sigma$-Algebra generated by $\varepsilon$. Further, if it holds that for a $\sigma$-Algebra A\\
	$$\sigma(\varepsilon) = A$$
	we call $\varepsilon$ the \textcolor{red}{generator} of A.	
\end{boxeddef}

\begin{example}
$\varepsilon = \left\{ \{1\} \right\}$ and $\mathcal{S} = \left\{ \left\{1, 2, 3\right\} \right\}$:\\
$\sigma(\varepsilon) = \sigma(\big\{ \{1\} \big\}) = \big\{\emptyset, \{1\}, \{2, 3\}, \{1, 2, 3\} \big\} $
\end{example}

\begin{boxeddef}[Topological Space]
A \textcolor{red}{topological space} is a tuple ($\mathcal{X}, \tau$) with $\mathcal{X}$ a set and $\tau$ a collection of subsets of $\mathcal{X}$ such that
	\begin{enumerate}
		\item $\emptyset, \mathcal{X} \in \tau$
		\item closed under \underline{union}, i.e.,\\
		 $$ \big\{ U_i \big\}_{i \in I} \subseteq \tau \implies \bigcup_{i \in I} U_i \in \tau$$
		\item closed under \underline{finite intersection}, i.e., \\
			$$\big\{ U_i \big\}_{i = 1}^n \subseteq \tau \implies \bigcap_{i = 1}^{n} U_i \in \tau$$
	\end{enumerate}
\textbf{Remark:} The elements of $\tau$ are called \underline{open sets}!
\end{boxeddef}

\begin{boxeddef}[Borel $\sigma$-Algebra]
	Given a topological space ($\mathcal{S}$, $\mathcal{O}$) with $\mathcal{O}$ denoting the system of open sets, then we call
	$$\mathcal{B}(s) := \sigma(\mathcal{O})$$
	the \textcolor{red}{Borel $\sigma$-Algebra} over $\mathcal{S}$. Its elements are called Borel sets.\\
	\newline
	$ \mathcal{S} = \mathbb{R}^n$, we write $\mathbb{B}^n := \mathbb{B}(\mathbb{R}^n)$\\
	
	Each of the following systems of sets are generators for $\mathbb{B}(\mathbb{R}^n) = \mathbb{B}^n$:
	\begin{enumerate}
		\item $\{U \subset \mathbb{R}^n$: U open $\}$
		\item $\{A \subset \mathbb{R}^n$: A closed$\}$
		\item $\big\{ ]a,b ] : a, b\in \mathbb{R}^n,\ a\subseteq b \big\} $
	\end{enumerate}
\end{boxeddef}

\paragraph{Convention:} We extend $\mathbb{R}$ by symbols "$-\infty$" and "$+\infty$" as\\
	$$ \overline{\mathbb{R}} = \mathbb{R} \cup \{+\infty, -\infty\} $$
	$$ \overline{\mathbb{B}} = \sigma\left(\mathbb{B} \cup \{+\infty\} \cup \{-\infty\} \right)$$

\begin{boxeddef}[Measurable space]
	\label{Measurable_Space}
	If $\mathcal{F}$ is a $\sigma$-Algebra over $\mathcal{S}$, we call ($\mathcal{S}$,$\mathcal{F}$) a \textcolor{red}{measurable space}. 
\end{boxeddef}

\begin{boxedsubdef}[Measurable maps/functions]
	Given $(\mathcal{S}_1, \mathcal{F}_1)$ and $(\mathcal{S}_2, \mathcal{F}_2)$, we call
	$$f: \mathcal{S}_1 \rightarrow \mathcal{S}_2$$
	a \textcolor{red}{measurable function} ($\mathcal{F}_1$-$\mathcal{F}_2$-measurable) if
	 $$\forall E \in \mathcal{F}_2: f^{-1}(E) \subset \mathcal{F}_1$$
\end{boxedsubdef}

\begin{example}
$1_A : \mathcal{S} \rightarrow \{0, 1\}$ indicator function of set $A \subset \mathcal{S}$
$$w \mapsto 1_A(w) \begin{cases}
	1, & \text{if}\ w \in A \\
	0, & else
\end{cases}$$
Consider $1_A$ as a function to $\mathbb{R}$.
\begin{itemize}
	\item if $\beta \leq 0$, then $\{w: 1_A(w)<\beta\} = \emptyset$
	\item if $\beta > 1$, then $\{w: 1_A(w)<\beta\} = \mathcal{S}$
	\item if $0 < \beta \leq 1$, then $\{w: 1_A(w)<\beta\} = \mathcal{S} \setminus A$
\end{itemize}
$\implies 1_A$ is measurable if $A \in \mathcal{F}$ ($\mathcal{S}$, $\mathcal{F}$)
\end{example}

\begin{boxeddef}[Measure]
	\label{measure}
	Let ($\mathcal{S,F}$) be a measurable space. A function
	$$\mu: F \rightarrow \bar{\mathbb{R}}$$
	is called a \textcolor{red}{measure} if the following conditions hold:
	\begin{enumerate}
		\item $\mu(\emptyset) = 0$
		\item $\mu(A) \geq 0$ for all $A \in \mathcal{F}$
		\item  for every sequence of $(A_n)_{n \in \mathbb{N}}$ of disjoint sets from $\mathcal{F}$, we have 
			\begin{equation}
				\tag{\textbf{$\sigma\text{-Additivity}$}}
				\mu \left(\bigcup_{i = 1}^{\infty} A_i\right) = \sum_{i = 1}^{\infty} \mu\left(A_i\right)
			\end{equation} 
	\end{enumerate}
\end{boxeddef}

\begin{boxedsubdef}[Measure space]
	Given a measurable space $\mathcal{(S, F)}$ and a measure $\mu: \mathcal{F} \rightarrow \bar{\mathbb{R}}$, we call
	$$\left(\mathcal{S, F}, \mu\right)$$
	a \textcolor{red}{measure space}.
\end{boxedsubdef}

\paragraph{Some important properties of measure spaces:} let A, B, $A_n \in \mathcal{F}$, $n \in \mathbb{N}$. Then
\begin{enumerate}
	\item if A and B are disjoint, then $\mu(A \cup B) = \mu(A) + \mu(B)$
	\item if $A \subset B$ and $\mu(A) < \infty$, then
	$$ \mu(B\setminus A) = \mu(B)-\mu(A)$$
	\item if $A \subset B$, then
	 $$\mu(A) \leq \mu(B)$$
	\item \begin{equation}
		\tag{\textbf{$\sigma\text{-sub-Additivity}$}}
		\mu (\bigcup_{i = 1}^{\infty} A_i) \leq \sum_{i = 1}^{\infty} \mu(A_i)
	\end{equation}
\end{enumerate}

\begin{boxeddef}[Probability Space]
	Given ($\mathcal{S}$, $\mathcal{F}$, $\mathcal{D}$) a measure space, with 
	$$\mathcal{D}(\mathcal{S}) = 1$$
	then we call $\mathcal{D}$ a \textcolor{red}{probability measure} and $\mathcal{(S, F, D)}$ a \textcolor{red}{probability space}.
	(A set $\mathcal{S}$, a sigma algebra $\mathcal{F}$ on that set, and a measure $\mathcal{D}$ that assigns to every element of $\mathcal{F}$ a probability (a number between 0 and 1)
\end{boxeddef}
\paragraph{Remark:} A possibility to construct, based on a measure space $(\mathcal{S}_1, \mathcal{F}_1, \mu)$ and a measurable function f from $\mathcal{S}_1$ to $\mathcal{S}_2$ (with $(\mathcal{S}_2, \mathcal{F}_2)$), another measure space $(\mathcal{S}_2, \mathcal{F}_2, \mu_{\mathcal{F}})$:
\begin{eqnarray*}
	\mu_\mathcal{F}: & \mathcal{F}_2 \rightarrow [0, \infty] \\
	 \mathcal{B}\mapsto & \mu_\mathcal{F}(\mathcal{B}) := \mu(f^{-1} (\mathcal{B}))
\end{eqnarray*}  
\begin{boxeddef}[Random variable]
	If $(\mathcal{S}_1, \mathcal{F}_1, \mathcal{D})$ is a probability space and $(\mathcal{S}_2, \mathcal{F}_2)$ a measurable space, then
	$$X: \mathcal{S}_1 \rightarrow \mathcal{S}_2$$
	is called a \textcolor{red}{random variable}. \\
	For $\mathcal{S}_2 = \mathbb{R}$, we call X a real random variable. The \textcolor{red}{push-forward measure} $\mathbb{P}_x$ on $(\mathcal{S}_2, \mathcal{F}_2)$ is also a probability measure.
	$$\underbrace{\mathbb{P}_x(\mathcal{S}_2)}_{\text{"distribution" of X}} = \mathcal{D}(X^{-1}(\mathcal{S}_2)) = \mathcal{D(S}_1) = 1$$
\end{boxeddef}
\paragraph{Conventions:}
\begin{eqnarray*}
\{ X \in A \} = \{w \in S: X(w) \in A \}\\
\{X = c\} = \{w \in S: X(w) = c\}\\
\mathbb{P}_x(A) = D\big(\{w \in S: X(w) \in A\}\big)\\
\mathbb{P}_x(\{c\}) = D\big(\{w \in S: X(w) = c\}\big)\\	
\end{eqnarray*}

\paragraph{Idea of Riemann Integral}:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{riemann_idea}
	\caption{Graphical Representation of Riemann Integration}
	\label{fig:riemannidea}
\end{figure}
Problems:
\begin{figure}[H]
\minipage{0.62\textwidth}
\begin{itemize}
	\item Difficult to extend to higher dimensions (3-d?)
	\item Reliance on continuity (what about discontinuous functions?)
	\item ...
\end{itemize}
\endminipage\hfill
\minipage{0.32\textwidth}
	\includegraphics[width=.5\linewidth]{riemann_problems}
	\label{fig:riemann_problems}
\endminipage\hfill
\end{figure}
\paragraph{Idea of Lebesgue-Integration} The key idea is to partition the range of a function $f: \mathcal{S} \to \mathbb{R}$ in intervals, to get an approximation by "elementary" functions.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{lebesgue_idea}
	\caption{Graphical Representation of Lebesgue Integration}
	\label{fig:lebesgueidea}
\end{figure}
We need a way to measure $A_i$. If we can do that, we can write:
$$ c_{i} \ . \ \underbrace{\mu(A_i)}_{\text{measure}}$$
... this will allow us to eventually write
$$ \sum_{i} c_i \mu(A_i) \ \text{  \underline{or}  }  \int_{\mathcal{S}}f d\mu$$

\paragraph{In a little bit more detail} In particular, lets look at case of "simple" functions. Say, we have $\mathcal{(S, F,}$ $\mu$), $\mu: \mathcal{F} \to [0, \infty]$.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{leb_detail}
	\caption{Illustration of indicator function of A}
	\label{fig:lebdetail}
\end{figure}
Any reasonable integration of $1_A$ should return $\mu_A$.
$$ \underbrace{I(1_A)}_{\text{integral}} = \mu_A$$
What is a "simple" function? $ f(x) = \sum_{i=1}^{n} c_i \cdot 1_{A_{i}} \cdot (x), \ \ A_i \in \mathcal{F}, c_i \in \mathbb{R}$\\
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{simple_leb}
	\caption{Graphical Representation of simple Lebesgue- 	integrable function}
	\label{fig:simplefun}
\end{figure}


We can define the interval of f via
$$ I(f) = \sum_{i = 1}^{n} c_i \cdot \mu(A_i)$$
Problem: $\mu: \mathcal{F} \to [0, \infty], c_i \in \mathbb{R} \implies$ so, we could get something like $10 \cdot \infty - 3 \cdot \infty$.\newline

Solution: $\{f: \mathcal{S} \to \mathbb{R}\ \big| \ \text{f is "simple" and } f \geq 0\} = T^+
$\\

For $f \in T^+$, we have a representation of f as
$$f(x) = \sum_{i=1}^{n} c_i \cdot 1_{A_i}(x) \text{ with } c_i \geq 0$$
and we define the lebesgue integral as 
$$ I(f) = \sum_{i=1}^{n} c_i \cdot \mu_{A_i} \text{ or } \int f d_{\mu} \text{ , or } \int f(x) d_{\mu}(x)$$

\paragraph{Properties} 
\begin{enumerate}
	\item For f, g $\in T^+$, and $\alpha, \beta \geq 0$ 
	
	\begin{equation}
		\tag{\textbf{Linearity}}
	 	\int \left(\alpha f + \beta g\right)d_\mu = \alpha\int fd_\mu + \beta\int gd_\mu
	 \end{equation}
	\item  if $f, g \in T^+$ and $ f \leq g$, it follows that 
	\begin{equation}
		\tag{\textbf{Monotonicity}}
		\int fd_\mu \leq \int gd_\mu
	\end{equation}
\end{enumerate}
This construction extends to all measurable functions $f:\mathcal{ S}\to \mathbb{R}\ $ !

\begin{boxeddef}[Expected value of a random variable]
	Given a probability space $\mathcal{(S, F, D)}$ and a (quasi-integrable) real random variable $X: \mathcal{S} \to \mathbb{R}$, then
	$$ \mathbb{E}[X] = \int XdD$$
	is the \textcolor{red}{expected value} of X.
\end{boxeddef}
\paragraph{Properties}
\begin{enumerate}
	\item if $X\geq 0$, then $\mathbb{E}[X] \geq 0$
	\item $\mathbb{E}[X+Y] = \mathbb{E}[X] + \mathbb{E}[Y]$ for random variables $X$ and $Y$
\end{enumerate}
\begin{boxeddef}[Markov Inequality]
	Given a probability space $\mathcal{(S, F, D)}$ and a non-negative ($\geq 0$) random variable X, we have for $ a > 0$ 
	$$ \mathbb{P}[X\geq a] \leq \frac{\mathbb{E}[X]}{a}$$
	$$ \Big( \mathbb{P}[X\geq a] = D\big(\{\omega \in \mathcal{S}: X(\omega) \geq a \} \big)\Big)$$
\end{boxeddef}
\begin{proof}
	We define $\Phi: \mathcal{S} \to \mathbb{R}$ with
	$$ \Phi(x) = \begin{cases}
		a, & \text{if}\ X \leq a \\
		0, & \text{if}\ X < a
	\end{cases} $$
	$\implies O \leq \Phi(X) \leq X(x)$. Hence, by monotonicity, we have
	\begin{equation*}
	\begin{split}
		\int Xd\mathcal{D} &\geq \int \Phi d\mathcal{D}\\
				&= a\cdot \mathcal{D}\big( \{\omega \in\mathcal{ S}: X(\omega) \geq a\}\big)
	\end{split}		
	\end{equation*}
	
	Divide by $a>0$
	$$ \implies \frac{1}{a} \cdot \int Xd\mathcal{D} \ \geq \mathcal{D}\big( \{\omega \in \mathcal{S}: X(\omega \geq a) \} \big) = \mathbb{P}[X\geq a]$$
	Since $\int Xd\mathcal{D}$ is $\mathbb{E}[X]$, we get $\mathbb{P}[X\geq a]\leq \frac{\mathbb{E}[X]}{a}$
\end{proof}
%
%\part{Actual ML lecture content}
%Recap of our setup:
%\begin{enumerate}
%	\item DOMAIN set X; we call $x\in X$ an instance
%	\item LABEL set Y; e.g. $Y = \{0, 1\}$ (for a binary problem)
%	\item TRAINING set $S = \big((x_1, y_1), ..., (x_m, y_m)\big)$  with $x_i \in X, y_i \in Y$
%	\item a LEARNER that receives S and outputs 
%	$$ h: X \to Y$$
%	which we call a hypothesis
%\end{enumerate}
%Assumption: for now, we assume $x_i$'s are drawn iid from some probability measure D over the domain and labelled by some function $f: X \to Y$:
%$$ x_i \underbrace{ \sim }_{\text{\scriptsize"drawn from"}} D,\ y_i = f(x_i)$$
\end{document}